{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9765869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c591f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_points = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(gray, 1.3, 5)\n",
    "    return face_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6043051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_face(facearray):\n",
    "    model = joblib.load('face_recognition_model2.pkl')\n",
    "    return model.predict(facearray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53a0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread('siddhsample.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "272ef1aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'face_recognition_model2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m cv2\u001B[38;5;241m.\u001B[39mrectangle(frame, (x, y), (x \u001B[38;5;241m+\u001B[39m w, y \u001B[38;5;241m+\u001B[39m h), (\u001B[38;5;241m255\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m20\u001B[39m), \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      3\u001B[0m face \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mresize(frame[y:y \u001B[38;5;241m+\u001B[39m h, x:x \u001B[38;5;241m+\u001B[39m w], (\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m))\n\u001B[1;32m----> 4\u001B[0m identified_person \u001B[38;5;241m=\u001B[39m \u001B[43midentify_face\u001B[49m\u001B[43m(\u001B[49m\u001B[43mface\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "Cell \u001B[1;32mIn[7], line 2\u001B[0m, in \u001B[0;36midentify_face\u001B[1;34m(facearray)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21midentify_face\u001B[39m(facearray):\n\u001B[1;32m----> 2\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mjoblib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mface_recognition_model2.pkl\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\u001B[38;5;241m.\u001B[39mpredict(facearray)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\numpy_pickle.py:650\u001B[0m, in \u001B[0;36mload\u001B[1;34m(filename, mmap_mode)\u001B[0m\n\u001B[0;32m    648\u001B[0m         obj \u001B[38;5;241m=\u001B[39m _unpickle(fobj)\n\u001B[0;32m    649\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 650\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m    651\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m _read_fileobject(f, filename, mmap_mode) \u001B[38;5;28;01mas\u001B[39;00m fobj:\n\u001B[0;32m    652\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fobj, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    653\u001B[0m                 \u001B[38;5;66;03m# if the returned file object is a string, this means we\u001B[39;00m\n\u001B[0;32m    654\u001B[0m                 \u001B[38;5;66;03m# try to load a pickle file generated with an version of\u001B[39;00m\n\u001B[0;32m    655\u001B[0m                 \u001B[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'face_recognition_model2.pkl'"
     ]
    }
   ],
   "source": [
    "(x, y, w, h) = extract_faces(frame)[0]\n",
    "cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 20), 2)\n",
    "face = cv2.resize(frame[y:y + h, x:x + w], (100, 100))\n",
    "identified_person = identify_face(face.reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718ff672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raghav_84\n"
     ]
    }
   ],
   "source": [
    "print(identified_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe162c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e759167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
